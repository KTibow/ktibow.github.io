<!doctype html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="stylesheet" href="/base.css" />
    <meta name="accent-color" content="#324AD5" />
    <title>Why is Phi 4 Multimodal so cheap?</title>
  </head>
  <body class="bg-neutral-900 text-white">
    <main class="prose prose-invert mx-auto my-4">
      <h1>Why is Phi 4 Multimodal so cheap?</h1>
      <p>Phi 4 Multimodal is the current cheapest transcription model, as this table shows:</p>
      <table>
        <thead>
          <tr>
            <th>Model</th>
            <th>Inputs</th>
            <th>Outputs</th>
            <th>Pricing</th>
          </tr>
        </thead>
        <tr>
          <td>GPT 4o transcribe</td>
          <td>$6/mtok, ~750/min</td>
          <td>$10/mtok</td>
          <td>~$0.36/hour</td>
        </tr>
        <tr>
          <td>GPT 4o mini transcribe</td>
          <td>$3/mtok, ~750/min</td>
          <td>$5/mtok</td>
          <td>~$0.18/hour</td>
        </tr>
        <tr>
          <td>Whisper Large (OpenAI)</td>
          <td rowspan="3">6000 frames/min pre-conv, 3000/min post-conv</td>
          <td rowspan="3">-</td>
          <td>$0.36/hour</td>
        </tr>
        <tr>
          <td>Whisper Large (DeepInfra)</td>
          <td>$0.027/hour</td>
        </tr>
        <tr>
          <td>Whisper Large Turbo (DeepInfra)</td>
          <td>$0.012/hour</td>
        </tr>
        <tr>
          <td>Gemini 2.0 Flash Lite</td>
          <td>$0.075/mtok, 1920/min</td>
          <td>$0.3/mtok</td>
          <td>$0.011/hour</td>
        </tr>
        <tr>
          <td>Phi 4 Multimodal</td>
          <td>$0.05/mtok, 750/min</td>
          <td>$0.1/mtok</td>
          <td>$0.003/hour</td>
        </tr>
      </table>
      <p>* <em>Assuming 150 output tokens/minute</em></p>
      <p>Why?</p>
      <ul>
        <li>Phi 4 uses few tokens to represent speech.</li>
        <li>Phi 4 has a low price per token, because DeepInfra can host it, because it's an open model.</li>
      </ul>
    </main>
  </body>
</html>
