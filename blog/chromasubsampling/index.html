<!doctype html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="stylesheet" href="/base.css" />
    <meta name="accent-color" content="#324AD5" />
    <title>Why do we still use chroma subsampling @KTibow</title>
  </head>
  <body class="bg-neutral-900 text-white">
    <div class="bg">
      <img src="./gradient-crop.avif" class="bg" />
    </div>
    <main class="prose prose-invert mx-auto my-4">
      <h1>Why do we still use chroma subsampling</h1>
      <p>
        Chroma subsampling is a simple idea. Our eyes are more sensitive to
        colors than they are to light, and most colors within a range are close
        to each other, so we can only send the chroma for every 4 pixels instead
        of for every 1.
      </p>
      <img
        src="https://upload.wikimedia.org/wikipedia/commons/f/f2/Common_chroma_subsampling_ratios.svg"
        class="bg-neutral-300 rounded-2xl p-1 w-full"
      />
      <p>
        Our eyes can barely tell the difference. As such, this system is used in
        basically all lossy image formats. JPEG? Used it since the start. AVIF
        and WEBP? On by default. You can find it anywhere.
      </p>
      <p>
        However, there's a problem. As you can see in the diagram, if pixels are
        close together with different chromas, they end up being different.
        Here's an example where you can really see the artifacts:
      </p>
      <div class="grid md:grid-cols-2 gap-2">
        <div class="bg-neutral-800 rounded-lg p-2">
          Original
          <img
            src="https://upload.wikimedia.org/wikipedia/commons/5/54/444-original-single-field.png"
            class="rounded-2xl"
          />
        </div>
        <div class="bg-neutral-800 rounded-lg p-2">
          Chroma subsampled
          <img
            src="https://upload.wikimedia.org/wikipedia/commons/8/8e/420-progressive-single-field.png"
            class="rounded-2xl"
          />
        </div>
      </div>
      <p>
        I was thinking about this for a while, and came up with some ideas but
        eventually came to a conclusion. Here's how that all went in my head.
      </p>

      <h2>attempt 1: use more pixels with a gradient system</h2>
      <p>
        Instead of mapping every 4 pixels to 1 chroma, how about we map every 8
        pixels to 2 chromas? We have one chroma for the low luminance, another
        chroma for a high luminance, and create a gradient between them.
      </p>
      <p>
        This would help in cases like the above. It might also generally improve
        image quality.
      </p>
      <p>
        On the other hand, if each box is the same luminance but with different
        chroma, that would create <em>more</em> artifacts. So I went back to the
        drawing board.
      </p>

      <h2>attempt 2: dynamic subsampling ranges</h2>
      <p>
        What if instead of always using a 2x2 grid to subsample, we vary the
        width to minimize artifacts? For example, in the example images above,
        we would have a long red strip, a long green strip, and a long red
        strip, and the place where the boundary is would match up with the place
        where the chroma changes.
      </p>
      <p>
        This could work just fine. We could even add back attempt 1's system
        conditionally if it would improve quality. We could also make it so that
        the height could vary. But wait... are we just reinventing image
        compression?
      </p>

      <h2>realization: we shouldn't really use chroma subsampling</h2>
      <p>
        Chroma subsampling relies on the ideas that our eyes are less sensitive
        to certain parts and that there are big parts of images similar in one
        way in another. But those are the same ideas that image compression
        already uses.
      </p>
      <p>
        Chroma subsampling essentially makes two versions of the image, a
        grayscale one at full res and a chroma one at half res. But since we
        already have the ability to vary our quality, why not just apply more
        lossy compression to the chroma? Surely that would be more effective
        than a simple downscale?
      </p>
      <p>
        I don't know. I haven't made any codecs myself. I just find it funny
        that essentially all lossy codecs still use this system by default.
      </p>
    </main>
    <style>
      .bg {
        position: absolute;
        top: 0;
        width: 100%;
        height: 32rem;
        z-index: -1;
      }
      .bg img {
        position: absolute;
        inset: 0;
        object-fit: cover;
        object-position: top;
      }
      .bg::after {
        position: absolute;
        content: "";
        inset: 0;
        background: linear-gradient(
          to bottom,
          rgb(23 23 23 / 0.6) 0%,
          rgb(23 23 23 / 0.612) 10%,
          rgb(23 23 23 / 0.636) 20%,
          rgb(23 23 23 / 0.704) 40%,
          rgb(23 23 23 / 0.792) 60%,
          rgb(23 23 23 / 0.892) 80%,
          rgb(23 23 23 / 0.944) 90%,
          rgb(23 23 23 / 1) 100%
        );
      }
    </style>
  </body>
</html>
